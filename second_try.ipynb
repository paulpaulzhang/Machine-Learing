{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #导入Pandas\n",
    "import numpy as np #导入Numpy\n",
    "import jieba #导入结巴分词\n",
    " \n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    " \n",
    "from __future__ import absolute_import #导入3.x的特征函数\n",
    "from __future__ import print_function\n",
    " \n",
    "neg=pd.read_excel('neg.xls',header=None,index=None)\n",
    "pos=pd.read_excel('pos.xls',header=None,index=None) #读取训练语料完毕\n",
    "pos['mark']=1\n",
    "neg['mark']=0 #给训练语料贴上标签\n",
    "pn=pd.concat([pos,neg],ignore_index=True) #合并语料\n",
    "neglen=len(neg)\n",
    "poslen=len(pos) #计算语料数目\n",
    " \n",
    "cw = lambda x: list(jieba.cut(x)) #定义分词函数\n",
    "pn['words'] = pn[0].apply(cw)\n",
    " \n",
    "comment = pd.read_csv('datasets\\train.csv') #读入评论内容\n",
    "#comment = pd.read_csv('a.csv', encoding='utf-8')\n",
    "comment = comment[comment['review'].notnull()] #仅读取非空评论\n",
    "comment['words'] = comment['review'].apply(cw) #评论分词 \n",
    " \n",
    "d2v_train = pd.concat([pn['words'], comment['words']], ignore_index = True) \n",
    " \n",
    "w = [] #将所有词语整合在一起\n",
    "for i in d2v_train:\n",
    "    w.extend(i)\n",
    "    \n",
    "dict = pd.DataFrame(pd.Series(w).value_counts()) #统计词的出现次数\n",
    "del w,d2v_train\n",
    "dict['id']=list(range(1,len(dict)+1))\n",
    " \n",
    "get_sent = lambda x: list(dict['id'][x])\n",
    "pn['sent'] = pn['words'].apply(get_sent) #速度太慢\n",
    " \n",
    "maxlen = 50\n",
    " \n",
    "print(\"Pad sequences (samples x time)\")\n",
    "pn['sent'] = list(sequence.pad_sequences(pn['sent'], maxlen=maxlen))\n",
    " \n",
    "x = np.array(list(pn['sent']))[::2] #训练集\n",
    "y = np.array(list(pn['mark']))[::2]\n",
    "xt = np.array(list(pn['sent']))[1::2] #测试集\n",
    "yt = np.array(list(pn['mark']))[1::2]\n",
    "xa = np.array(list(pn['sent'])) #全集\n",
    "ya = np.array(list(pn['mark']))\n",
    " \n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(dict)+1, 256))\n",
    "model.add(LSTM(256, 128)) # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, 1))\n",
    "model.add(Activation('sigmoid'))\n",
    " \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', class_mode=\"binary\")\n",
    " \n",
    "model.fit(x, y, batch_size=16, nb_epoch=10) #训练时间为若干个小时\n",
    " \n",
    "classes = model.predict_classes(xt)\n",
    "acc = np_utils.accuracy(classes, yt)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
